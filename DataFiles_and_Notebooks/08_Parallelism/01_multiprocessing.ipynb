{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../00_AdvancedPythonConcepts/talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AUV1r1xvhBdPF6lX-2SJLkO-vkkmCXEDrMwB/image.png\">\n",
    "http://www.slideshare.net/ManojitNandi/parallel-programming-in-python-speeding-up-your-analysis\n",
    "\n",
    "Remember, you can create (fork) many processes, which are copies of the original parent process (memory, data, state) and act independently of each other. To share data between them you have to explicitly do that within each process. The Pythonic way we do multiprocessing (creation of new processes, communication between processes) is with `multiprocessing`.\n",
    "\n",
    "*\"effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.\"*\n",
    "\n",
    "- https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analog to `threading.Thread` is `multiprocessing.Process`. You should be able to do a drop-in replacement. Instead of `current_thread()` you'd use `os.getpid()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) worker: 0 sleeping for 3 s, name: 1464\n",
      "(MainThread) worker: 1 sleeping for 4 s, name: 1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/dc/1sk9z_cx15s7g6895fqjlp7h0000gn/T/tmp3zf50da1'. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) done\n",
      "(MainThread) done\n"
     ]
    }
   ],
   "source": [
    "%%snakeviz\n",
    "\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.handlers = []\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    \n",
    "    sleep_time = random.randint(1,5)\n",
    "    logging.debug('worker: {0} sleeping for {1} s, name: {2}'\n",
    "                   .format(num,sleep_time,os.getpid()))\n",
    "    time.sleep(sleep_time)\n",
    "    logging.debug('done')\n",
    "    return\n",
    "\n",
    "procs = []\n",
    "for i in range(2):\n",
    "    p = multiprocessing.Process(target=worker, args=(i,))\n",
    "    procs.append(p)\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your machine has multiple cores, these two processes may get run on those two separate cores, independently.\n",
    "\n",
    "You may need to share info between processes. You can do this, just like with Threads with `Queues`. You can also use the (UNIX-like) Pipe to have  two processes communicate with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "# https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes\n",
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pools of workers (in separate processes) with multiprocessing Pool.\n",
    "\n",
    "https://docs.python.org/3.5/library/multiprocessing.html#using-a-pool-of-workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool \n",
    "pool = Pool(processes=4)     # start 4 worker processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool at 0x104b62940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def g(x):\n",
    "    # domain specific stuff here!\n",
    "    time.sleep(0.2)\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 ms, sys: 1.49 ms, total: 4.06 ms\n",
      "Wall time: 2.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time list(map(g,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 ms, sys: 2.54 ms, total: 5.11 ms\n",
      "Wall time: 605 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pool.map(g,range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 1 9 25 36 16 49 64 81 "
     ]
    }
   ],
   "source": [
    "# print same numbers in arbitrary order\n",
    "for i in pool.imap_unordered(g, range(10)):\n",
    "    print(i,sep=\" \",end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is packaging (pickling) up your functions and sending them to different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x104c81488>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ea45574c21dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jbloom/anaconda/envs/seminar/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jbloom/anaconda/envs/seminar/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jbloom/anaconda/envs/seminar/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    383\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jbloom/anaconda/envs/seminar/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jbloom/anaconda/envs/seminar/lib/python3.5/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x104c81488>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "pool.map(lambda x: x**3, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# run only one process \"g(10)\" asynchronously \n",
    "result = pool.apply_async(g, [10])\n",
    "\n",
    "# prints \"100\" unless you timeout\n",
    "print(result.get(timeout=0.25)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x104bc3278>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 *****\n",
      "0.5565 sec\n",
      "2 *****\n",
      "0.3939 sec\n",
      "3 *****\n",
      "0.3765 sec\n",
      "4 *****\n",
      "0.3558 sec\n",
      "8 *****\n",
      "0.4504 sec\n",
      "16 *****\n",
      "0.3872 sec\n",
      "32 *****\n",
      "0.4038 sec\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool \n",
    "import time\n",
    "\n",
    "def f(x): \n",
    "    return x*x\n",
    "\n",
    "for i in [1,2,3,4,8,16,32]:\n",
    "    print(i,\"*\"*5,flush=True)\n",
    "    pool = Pool(processes=i)               # start 4 worker processes \n",
    "    start = time.time()\n",
    "    pool.map(f, range(1000000))\n",
    "    print(\"{0:0.4f} sec\".format(time.time() - start))\n",
    "    pool.terminate()\n",
    "    del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core file size          (blocks, -c) 0\r\n",
      "data seg size           (kbytes, -d) unlimited\r\n",
      "file size               (blocks, -f) unlimited\r\n",
      "max locked memory       (kbytes, -l) unlimited\r\n",
      "max memory size         (kbytes, -m) unlimited\r\n",
      "open files                      (-n) 256\r\n",
      "pipe size            (512 bytes, -p) 1\r\n",
      "stack size              (kbytes, -s) 8192\r\n",
      "cpu time               (seconds, -t) unlimited\r\n",
      "max user processes              (-u) 709\r\n",
      "virtual memory          (kbytes, -v) unlimited\r\n"
     ]
    }
   ],
   "source": [
    "!ulimit -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `concurrent.futures` - Launching parallel tasks\n",
    "\n",
    "Built-in, create different pools for executing **maps** (single loop over data). Local resources.\n",
    "\n",
    "`The concurrent.futures module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with threads, using ThreadPoolExecutor, or separate processes, using ProcessPoolExecutor. Both implement the same interface, which is defined by the abstract Executor class.`\n",
    "\n",
    "https://docs.python.org/3/library/concurrent.futures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor(2)  # can also use a threadpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.14 ms, sys: 2.9 ms, total: 11 ms\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from time import sleep\n",
    "\n",
    "results = []\n",
    "for i in range(8):\n",
    "    sleep(1)\n",
    "    results.append(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 ms, sys: 11.6 ms, total: 24 ms\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from time import sleep\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor(2) \n",
    "\n",
    "def slowfunc(x):\n",
    "    sleep(1)\n",
    "    return(x+1)\n",
    "\n",
    "results = list(e.map(slowfunc,range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figured out I have 4 cores and ran it in 4 separate processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout\n",
    "\n",
    "Convert the sequential code to parallel using `concurrent.futures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "\n",
    "lens = []\n",
    "for i in range(10):\n",
    "    a = requests.get(url)\n",
    "    resp = a.text\n",
    "    print(\"title=\",BeautifulSoup(resp, 'html.parser')\n",
    "          .title.string.split(\"- Wikipedia\")[0],\"len=\",len(resp))\n",
    "    lens.append(len(resp))\n",
    "\n",
    "print(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor.submit\n",
    "\n",
    "`submit` starts an execution in a separate thread or process and immediately returns a `Future` object that points back to the result. Until the function completes, the future is pending. We get the result of a task with `.result()`, which blocks until the computation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.52 ms, sys: 16.4 ms, total: 22.9 ms\n",
      "Wall time: 21.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from time import sleep\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor() \n",
    "\n",
    "def slowfunc(x,y,delay=1):\n",
    "    sleep(delay)\n",
    "    return(x+y)\n",
    "\n",
    "future = e.submit(slowfunc,1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x104cb2940 state=finished returned int>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.05 ms, sys: 4.02 ms, total: 13.1 ms\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "futures = [e.submit(slowfunc,1,2, delay=1) for _ in range(10)]\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joblib\n",
    "\n",
    "http://pythonhosted.org/joblib/\n",
    "\n",
    "Running Python functions as pipeline jobs. The *vision is to provide tools to easily achieve better performance and reproducibility when working with long running jobs.* Specifically meant to work well with large data (ie. numpy arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - **Avoid computing twice the same thing**: code is rerun over an over, for instance when prototyping computational-heavy jobs (as in scientific development), but hand-crafted solution to alleviate this issue is error-prone and often leads to unreproducible results\n",
    "  - **Persist to disk transparently**: persisting in an efficient way arbitrary objects containing large data is hard. Using joblib’s caching mechanism avoids hand-written persistence and implicitly links the file on disk to the execution context of the original Python object. As a result, joblib’s persistence is good for resuming an application status or computational job, eg after a crash.\n",
    "\n",
    "Joblib strives to address these problems while leaving your code and your flow control as unmodified as possible (no framework, no new paradigms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!conda install joblib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "[sqrt(i ** 2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Helpers\n",
    "\n",
    "Joblib provides a simple helper class to write parallel for loops using multiprocessing. The core idea is to write the code to be executed as a generator expression, and convert it to parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Parallel uses the Python multiprocessing module to fork separate Python worker processes to execute tasks concurrently on separate CPUs. This is a reasonable default for generic Python programs but it induces some overhead as the input and output data need to be serialized in a queue for communication with the worker processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=2,backend=\"threading\") \\\n",
    "  (delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed:   13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.16140079498291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:   20.0s finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "Parallel(n_jobs=5,verbose=5) \\\n",
    "  (delayed(time.sleep)(1) for _ in range(100))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On demand recomputing: the `Memory` class\n",
    "\n",
    "Caching long running results so it can be reused. Let's try to cache to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "memory = Memory(cachedir=\"/tmp/\", verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def f(x):\n",
    "    print('Running f(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    2.4s, 0.0min: Loading f...\n",
      "___________________________________________________f cache loaded - 0.0s, 0.0min\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(f(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    8.8s, 0.1min: Loading f...\n",
      "___________________________________________________f cache loaded - 0.0s, 0.0min\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(f(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]   18.1s, 0.3min: Loading f...\n",
      "___________________________________________________f cache loaded - 0.0s, 0.0min\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(f(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--Users-jbloom-Classes-python-seminar-DataFiles_and_Notebooks-08_Parallelism-__ipython-input__.f...\n",
      "f(20)\n",
      "Running f(20)\n",
      "________________________________________________________________f - 0.0s, 0.0min\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(f(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxr-xr-x  6 jbloom  wheel  204 Sep 23 15:14 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  4 jbloom  wheel  136 Sep 23 15:14 \u001b[34m384f3b7270f5bd1b16f875a18665c26e\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  5 jbloom  wheel  170 Sep 23 11:42 \u001b[34m..\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  4 jbloom  wheel  136 Sep 23 11:41 \u001b[34m1d57c12eb7e5ebcc7910478490915e9a\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  4 jbloom  wheel  136 Sep 23 11:41 \u001b[34md3ffa92536e9b2aeb96c6d0e11ccd857\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 jbloom  wheel   84 Sep 23 11:41 func_code.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lat /tmp/joblib/__main__--Users-jbloom-Classes-python-seminar-DataFiles_and_Notebooks-08_Parallelism-__ipython-input__/f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "memory = Memory(cachedir=\"/tmp/\",verbose=10,mmap_mode=\"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def josh(x,blah=True):\n",
    "    print('Running g(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--Users-jbloom-Classes-python-seminar-DataFiles_and_Notebooks-08_Parallelism-__ipython-input__.josh...\n",
      "josh(1)\n",
      "Running g(1)\n",
      "_____________________________________________________________josh - 0.0s, 0.0min\n",
      "[Memory]   17.0s, 0.3min: Loading josh from /tmp/joblib/__main__--Users-jbloom-Classes-python-seminar-DataFiles_and_Notebooks-08_Parallelism-__ipython-input__/josh/5af310b98119c5e5b1a775c624b66fb1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(josh(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]   26.0s, 0.4min: Loading josh from /tmp/joblib/__main__--Users-jbloom-Classes-python-seminar-DataFiles_and_Notebooks-08_Parallelism-__ipython-input__/josh/5af310b98119c5e5b1a775c624b66fb1\n",
      "________________________________________________josh cache loaded - 0.0s, 0.0min\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(josh(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(g(1,blah=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache(ignore=['blah'])\n",
    "def h(x,blah=True):\n",
    "    print('Running h(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(h(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(h(1,blah=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: joblib also gives (for persistence) `joblib.dump()` and `joblib.load()` provide a replacement for pickle to work efficiently on Python objects containing large data, in particular large numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
