{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "Classification & Regression Trees (CART)\n",
    "\n",
    "<img src=\"https://littleml.files.wordpress.com/2013/03/iris_dataset_model.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AUVOiUntlxZHM60VXN8WZWzg83pzEIL-XJwB/image.png\" width=\"50%\">\n",
    "\n",
    "Building Trees Rigorously (Node Splitting Criteria)\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUVA6K4mqnhOMoNcy93La3lFe5XOAxgaWrUB/image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections of Trees (\"Decision Forests\", \"Random Forests\")\n",
    "\n",
    "<img src=\"https://contentmamluswest001.blob.core.windows.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/b729c21014a34955b20fa94dc13390e5/image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying NIST Handwritten Digits\n",
    "\n",
    "We will try to classify handwritten digits (0-9) from their raw pixelated images.\n",
    "\n",
    "Each image is 8 $\\times$ 8 pixels.  We will not do any feature extraction and instead classify based on the intensity values for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "# import NIST digits data set (1797 8x8 images)\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "f,axs = plt.subplots(1,10,figsize=(16, 6))\n",
    "objarr = np.empty_like(axs)\n",
    "for n, ax in enumerate(axs.flat):\n",
    "    objarr.flat[n] = ax.imshow(digits['images'][n], cmap='gray', interpolation='nearest')\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Now we split the data into a training and testing set.}$\n",
    "\n",
    "$\\textbf{We will only fit the classifier on the training set and use the testing set to evaluate performance.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first 500 as training\n",
    "train = 500\n",
    "Xtr = digits['data'][:train]\n",
    "Ytr = digits['target'][:train]\n",
    "print(\"training size: \" + str(len(Ytr)))\n",
    "\n",
    "# testing set\n",
    "Xte = digits['data'][train:]\n",
    "Yte = digits['target'][train:]\n",
    "print(\"testing size: \" + str(len(Yte)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate classifier object\n",
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# fit the classification model on training set\n",
    "classifier.fit(Xtr, Ytr)\n",
    "\n",
    "# make predictions for testing set\n",
    "pred_rf = classifier.predict(Xte) \n",
    "\n",
    "print(\"True Class / Predicted class\")\n",
    "print(np.vstack((Yte[0:10],pred_rf[0:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs.stanford.edu/people/karpathy/svmjs/demo/demoforest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Estimation\n",
    "\n",
    "Q: What evaluation metrics are available?\n",
    "\n",
    "<b>Loss Functions</b>\n",
    "\n",
    "- `metrics.zero_one(y_true, y_pred)`\n",
    "Zero-One classification loss\n",
    "- `metrics.hinge_loss(y_true, pred_decision[, ...])`\n",
    "Cumulated hinge loss (non-regularized).\n",
    "- `metrics.mean_square_error(y_true, y_pred)`\n",
    "Mean square error regression loss\n",
    "\n",
    "<b>Score Functions</b>\n",
    "\n",
    "- `metrics.zero_one_loss(y_true, y_pred)`\n",
    "Zero-One classification score\n",
    "- `metrics.auc(x, y)`\n",
    "Compute Area Under the Curve (AUC)\n",
    "- `metrics.precision_score(y_true, y_pred[, ...])`\n",
    "Compute the precision\n",
    "- `metrics.recall_score(y_true, y_pred[, pos_label])`\n",
    "Compute the recall\n",
    "- `metrics.fbeta_score(y_true, y_pred, beta[, ...])`\n",
    "Compute fbeta score\n",
    "- `metrics.f1_score(y_true, y_pred[, pos_label])`\n",
    "Compute f1 score\n",
    "\n",
    "<b>Evaluation Plots</b>\n",
    "- `metrics.confusion_matrix(y_true, y_pred[, ...])` Compute confusion matrix to evaluate the accuracy of a classification\n",
    "- `metrics.roc_curve(y_true, y_score)` Compute Receiver operating characteristic (ROC)\n",
    "- `metrics.precision_recall_curve(y_true, ...)` Compute precision-recall pairs for different probability thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute zero-one loss / score & confusion matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "rf_01 = metrics.zero_one_loss(Yte, pred_rf) # zero-one loss\n",
    "rf_01_score = metrics.accuracy_score(Yte, pred_rf) # zero-one score\n",
    "rf_confmat = metrics.confusion_matrix(Yte, pred_rf) # conf mat\n",
    "\n",
    "print(\"Zero-One Loss: \" + str(rf_01))\n",
    "print(\"Zero-One Score: \" + str(rf_01_score))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"[i, j] is the # of objects truly in group i but predicted to be in group j\")\n",
    "print(rf_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(rf_confmat, annot=True,  fmt='', \n",
    "            xticklabels=[str(x) for x in range(10)], yticklabels=[str(x) for x in range(10)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some digits that we get wrong\n",
    "wrong = np.where(pred_rf != Yte)[0][:9]\n",
    "\n",
    "f,axs = plt.subplots(3,3,figsize=(7, 7))\n",
    "objarr = np.empty_like(axs)\n",
    "\n",
    "for n, ax in enumerate(axs.flat):\n",
    "    objarr.flat[n] = ax.imshow(np.reshape(Xte[wrong[n]],(8,8)).astype(int),\n",
    "                              cmap='gray_r', interpolation='nearest')\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.set_title(\"True = \" + str(int(Yte[wrong[n]])) +\". Pred = \" + str(int(pred_rf[wrong[n]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision and recall\n",
    "# Note: precision & recall are for 2-class; multi-class returns weighted avg. prec/recall\n",
    "\n",
    "rf_precision = metrics.precision_score(Yte, pred_rf,average=\"weighted\") # TP / (TP + FP)\n",
    "rf_recall = metrics.recall_score(Yte, pred_rf,average=\"weighted\") # TP / (TP + FN)\n",
    "\n",
    "print(\"Avg. Precision: \",rf_precision)\n",
    "print(\"Avg. Recall: \", rf_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_rf_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ROC curve, AUC for RF classifier using digit = 1\n",
    "digit = 1\n",
    "Yte_1 = list(map(lambda x: x == digit and 1. or 0.,Yte)) # does Y = digit\n",
    "\n",
    "pred_rf_prob = classifier.predict_proba(Xte) \n",
    "\n",
    "pred_rf_prob_1 = pred_rf_prob[:,digit]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yte_1, pred_rf_prob_1)\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(5, 5))\n",
    "ax.plot(fpr,tpr,'b-',linewidth=3)\n",
    "ax.set_xlim([0.,0.3])\n",
    "ax.set_ylim([0.6,1.0005])\n",
    "ax.set_xlabel(\"False Positive Rate\",size=15)\n",
    "ax.set_ylabel(\"True Positive Rate\",size=15)\n",
    "ax.set_title(\"ROC Curve for NIST digit={} RF Classifier\".format(digit),size=22)\n",
    "print(\"AUC for digit={}: \".format(digit) + str(metrics.auc(fpr,tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Tuning the Classifier}$  \n",
    "======================================================\n",
    "\n",
    "For now we have used an RF classifier with the choice of `n_estimators` and the default parameters.\n",
    "\n",
    "Q: How do I choose which model and (hyper) parameters to use?\n",
    "\n",
    " - KNN with what # of neighbors?\n",
    " - SVM which what kernel & bandwidth?\n",
    " - RF with how many estimators and which max_features?\n",
    " - GP with what kernel & bandwidth?\n",
    " \n",
    "**Solution: use `grid_search.GridSearchCV`**:\n",
    "`grid_search.GridSearchCV(estimator, param_grid, loss_func, n_jobs, cv=None)`\n",
    "\n",
    "Computes cv-fold cross-validated loss_func (or score_func) of estimator over a param_grid on n_jobs cores, and returns the best model!\n",
    "\n",
    "Let's see how we can rigorously find the optimal model using cross-validation and grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best Random Forest classifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# explore 3 different forest sizes and 3 choices of mtry\n",
    "parameters = {'n_estimators':[20,50,100],  'max_features':[8,10,'auto'], \n",
    "             'criterion': ['gini','entropy']}\n",
    "rf_tune = model_selection.GridSearchCV(RandomForestClassifier(), parameters, \n",
    "                                   n_jobs = -1, cv = 5,verbose=1)\n",
    "rf_opt = rf_tune.fit(Xtr, Ytr)\n",
    "\n",
    "print(\"Best zero-one score: \" + str(rf_opt.best_score_) + \"\\n\")\n",
    "print(\"Optimal Model:\\n\" + str(rf_opt.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout 2\n",
    "\n",
    "Breakout\n",
    "Classify the famous Iris data, first used by R.A Fisher. \n",
    "To load in the data and split into training / testing sets:\n",
    "\n",
    "1. Choose your favorite classification model.  \n",
    "2. Find the parameters that minimize the 3-fold cross-validation misclassification rate over the training set.  \n",
    "3. Apply this optimized model to predict the class of each object in the held-out set.  \n",
    "\n",
    "a) What is your best 3-fold CV 0-1 score?\n",
    "\n",
    "b) What is your 0-1 score when applying it to testing set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "feature_importances = rf_opt.best_estimator_.feature_importances_\n",
    "feature_importances = feature_importances.reshape(8,8)\n",
    "print(feature_importances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(feature_importances, cmap=plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits['data']\n",
    "Y = digits['target']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "rfe = RFE(estimator=clf, n_features_to_select=1, step=1)\n",
    "rfe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "ranking = rfe.ranking_.reshape(digits.images[0].shape)\n",
    "sns.heatmap(ranking, cmap=plt.cm.viridis_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/rhiever/tpot/master/images/tpot-logo.jpg\" width=\"30%\"> \n",
    "\n",
    "Consider TPOT your Data Science Assistant. TPOT is a Python tool that automatically creates and optimizes machine learning pipelines using genetic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/rhiever/tpot/master/images/tpot-ml-pipeline.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data.astype(np.float64),\n",
    "    iris.target.astype(np.float64), train_size=0.75, test_size=0.25)\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_iris_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tpot_iris_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run tpot_iris_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
