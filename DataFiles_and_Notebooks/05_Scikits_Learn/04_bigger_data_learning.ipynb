{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While sklearn can be parallelized and extremely versitile in the breath of algorithms it exposes it is not built for \"medium\"/\"big\" data. Some algorithms are \"incremental\" in the sense that they can be updated with only a small window on the training data (see http://scikit-learn.org/stable/modules/scaling_strategies.html). But for many learning algorithms, data is usually kept in RAM (and potentially copied many times) so you typically cannot learn on data with featurized size $>$ 10% RAM.\n",
    "\n",
    "- `dask-learncv` is a new project that is attempting to expose much of sklearn capabilities but atop `dask.distributed` and hence do a lot of computation out of core (see https://github.com/dask/dask-searchcv). \n",
    "\n",
    "- `graphlab` (aka turi) is a Python 2.7 project for out-of-core learning and data-science pipeling (https://github.com/apple/turicreate).\n",
    "\n",
    "- `MLLib` sits atop Spark and is meant for large-scale distributed learning tasks (http://spark.apache.org/docs/latest/ml-guide.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install dask-searchcv -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Fit with dask-searchcv\n",
    "from dask_searchcv import GridSearchCV\n",
    "\n",
    "param_space = {'C': [1e-4, 1, 100],\n",
    "               'gamma': [1e-3, 1e-2, 1e-2, 1],\n",
    "               'class_weight': [None, 'balanced']}\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "search = GridSearchCV(model, param_space, cv=10, return_train_score=True)\n",
    "search.fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_.score(digits.data,digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
